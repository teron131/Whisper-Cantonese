# Data Processing Pipeline Overview

This document describes the structure of the datasets generated at various stages of the YouTube Cantonese data processing pipeline. The pipeline consists of the following steps:

1.  **Download Audio & Captions:** Raw audio (`.m4a`) and subtitle (`.srt`) files are downloaded from YouTube channels using `YouTube/download_channel.py`. The raw data is stored in the `data` directory.
2.  **Segment Audio:** The raw audio files are segmented based on subtitle timings using `YouTube/segment_audio.py`. The segmented audio (`.mp3`) and corresponding metadata (`.json`) are stored in the `dataset` directory.
3.  **Create Tar Archives:** Segmented audio/metadata pairs are grouped into TAR archives (`.tar`) suitable for use with Hugging Face Datasets (specifically WebDataset format) using `YouTube/create_tar.py`. These archives are stored in the `dataset_hf` directory.
4.  **Upload to Hugging Face Hub:** The generated TAR archives and a README are uploaded to a Hugging Face Dataset repository using `YouTube/create_dataset.py`.

# Raw Dataset Structure (`data` directory)

The dataset generated by the `channel_download.py` script is organized as follows:

1.  **Root Directory:** All data is stored within a main directory named `data`.
2.  **Channel Directory:** Inside the `data` directory, a subdirectory is created for each YouTube channel processed. The name of this subdirectory corresponds to the channel ID (extracted from the channel URL, e.g., `channel_id` from `https://www.youtube.com/@channel_id`). It can be obtained by:

```python
from pytubefix import Channel

channel = Channel(url)
channel_id = channel.channel_uri.replace("/@", "")
```

3.  **Video Content:** Within each channel directory (`data/{channel_id}/`), the following files are stored along with the video ID obtained from the URL (`https://youtube.com/watch?v=video_id`):
    - **Audio Files:** For each video that has captions available in the target languages (`zh-TW`, `zh-HK`, `zh-Hant`), an audio file (`.m4a`) is downloaded. The default sample rate is 44100 Hz. The filename is the video ID (e.g., `{video_id}.m4a`).
    - **Caption Files:** Corresponding caption files (`.srt`) are downloaded for the same videos. The filename matches the audio file, using the video ID (e.g., `{video_id}.srt`).
    - **Metadata CSV:** A single CSV file named after 'metadata.csv' (so it stays on top alphabetically) contains metadata about the videos for which audio and captions were successfully downloaded. This file includes the following columns:
      - `video_id`: The ID off the YouTube video.
      - `title`: The title of the YouTube video.
      - `watch_url`: The direct URL to the YouTube video.
      - `length`: The duration of the video in seconds.
      - `caption_code`: The language code of the caption file.

**Example Structure:**

```
data/
└── {channel_id}/ # Directory named after the channel ID
    ├── metadata.csv # CSV metadata for downloaded videos
    ├── {video_id_1}.mp3 # Audio file for video 1
    ├── {video_id_1}.srt # Caption file for video 1
    ├── {video_id_2}.mp3 # Audio file for video 2
    ├── {video_id_2}.srt # Caption file for video 2
    ├── ... # More audio/caption pairs
    ├── {video_id_n}.mp3 # Audio file for video n
    └── {video_id_n}.srt # Caption file for video n
```

# Segmented Dataset Structure (`dataset` directory)

The `dataset` directory contains segmented audio files derived from the raw audio in `data`, generated by `YouTube/segment_audio.py`. This script processes each raw audio/caption pair:

- **Subtitle Grouping:** Subtitles (`.srt`) are grouped into segments aiming for a maximum duration of approximately 30 seconds per group (`group_subtitles` function).
- **Audio Segmentation:** For each subtitle group, the corresponding audio segment is extracted from the raw `.m4a` file using `ffmpeg`. The segment only includes the parts of the audio corresponding to the subtitles within the group. The output is saved as an MP3 file with a sample rate of 16000 Hz.
- **Metadata Generation:** A JSON file (`.json`) is created alongside each segmented audio file. This file contains metadata about the segment, including channel ID, video ID, original video title/URL/length, caption language, and details of the individual subtitles within the group (index, start/end times, text).

Within the `dataset` directory, the structure is as follows:

- **Channel Directory:** Named after the channel ID, matching the channel directory in `data`.
- **Video Directory:** For each video/audio file, a subdirectory is created with the basename of the audio file (video ID).
- **Segmented Audio Files:** Within each video directory, the segmented audio files (`.mp3`) are stored. Files are named using the pattern `{video_id}_{group_name}.mp3`, where `{group_name}` is the index of the first subtitle in the group, or a range like `{first_idx}-{last_idx}` if the group contains multiple subtitles.
- **Segment Metadata Files:** Corresponding JSON files (`.json`) containing the segment metadata are stored alongside the audio files, named `{video_id}_{group_name}.json`.

**Example Structure of `dataset`:**

```
dataset/
└── {channel_id}/
    ├── {video_id_1}/
    │   ├── {video_id_1}_1-5.mp3
    │   ├── {video_id_1}_1-5.json
    │   ├── ...
    │   └── ...
    ├── {video_id_2}/
    │   ├── {video_id_2}_1.mp3
    │   ├── {video_id_2}_1.json
    │   └── ...
    └── ...
```

**Note:** The previous mention of a channel-level `metadata.csv` in the `dataset` directory was a planned feature but is not currently implemented by `segment_audio.py`. The metadata is stored per-segment in the JSON files.

# Hugging Face Dataset Structure (`dataset_hf` directory)

The `dataset_hf` directory contains TAR archives suitable for uploading to the Hugging Face Hub and loading with `datasets`. This structure is generated by `create_tar.py`.

- **Channel Directory:** Named after the channel ID, matching the channel directories in `data` and `dataset`.
- **TAR Archives:** Within each channel directory, segmented audio/metadata pairs are bundled into TAR archives (`.tar`). Each archive contains multiple `.mp3` and `.json` file pairs. The archives are named `{channel_id}_{shard_index:03d}.tar`. The maximum size of each shard is approximately 1 GiB.
- **README.md:** A `README.md` file is included at the root of `dataset_hf` for the Hugging Face dataset repository.

**Example Structure of `dataset_hf`:**

```
dataset_hf/
└── {channel_id}/
    ├── {channel_id}_000.tar
    ├── {channel_id}_001.tar
    └── ...
README.md
```
